import torch
import torch.nn.functional as F

# å®šä¹‰è¾“å…¥æ ·æœ¬æ•°å€¼
X1 = torch.tensor(1)
X2 = torch.tensor(2)
Y = torch.tensor(2)
Lr = 0.01

# å‚æ•°åˆå§‹åŒ–
w1_11 = torch.tensor(1.,requires_grad=True)
w1_12 = torch.tensor(1.,requires_grad=True)
w1_21 = torch.tensor(1.,requires_grad=True)
w1_22 = torch.tensor(-1.,requires_grad=True)
w2_11 = torch.tensor(1.,requires_grad=True)
w2_21 = torch.tensor(-1.,requires_grad=True)

ğœ½1_11, ğœ½1_12, ğœ½2_11 = torch.tensor([1.,1.,1.],requires_grad=True)

# å‰å‘ä¼ æ’­
y1_1 = w1_11*X1 + w1_21*X2 + ğœ½1_11
x2_1 = F.relu(y1_1)
y1_2 = w1_12*X1 + w1_22*X2 + ğœ½1_12
x2_2 = F.relu(y1_2)
A = w2_11*x2_1 + w2_21*x2_2 +ğœ½2_11

# Loss
Loss = (A-Y).pow(2)/2

Loss.backward()
print(w1_11.grad)

with torch.no_grad():
    w1_11 -= Lr*w1_11.grad

print(w1_11)
